{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-14 17:23:21--  https://mlbootcamp.ru/media/condition/mlboot_dataset.zip\n",
      "Resolving mlbootcamp.ru (mlbootcamp.ru)... 185.5.138.249\n",
      "Connecting to mlbootcamp.ru (mlbootcamp.ru)|185.5.138.249|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2738062403 (2.5G) [application/zip]\n",
      "Saving to: 'mlboot_dataset.zip'\n",
      "\n",
      "mlboot_dataset.zip  100%[===================>]   2.55G  59.7MB/s    in 45s     \n",
      "\n",
      "2018-07-14 17:24:06 (58.4 MB/s) - 'mlboot_dataset.zip' saved [2738062403/2738062403]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://mlbootcamp.ru/media/condition/mlboot_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mlboot_dataset.zip\n",
      "   creating: mlboot_dataset/\n",
      "  inflating: mlboot_dataset/mlboot_test.tsv.gz  \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/mlboot_dataset/\n",
      "  inflating: __MACOSX/mlboot_dataset/._mlboot_test.tsv.gz  \n",
      "  inflating: mlboot_dataset/.DS_Store  \n",
      "  inflating: __MACOSX/mlboot_dataset/._.DS_Store  \n",
      "  inflating: mlboot_dataset/mlboot_data.tsv.gz  \n",
      "  inflating: __MACOSX/mlboot_dataset/._mlboot_data.tsv.gz  \n",
      "  inflating: mlboot_dataset/mlboot_train_answers.tsv.gz  \n",
      "  inflating: __MACOSX/mlboot_dataset/._mlboot_train_answers.tsv.gz  \n",
      "  inflating: __MACOSX/._mlboot_dataset  \n"
     ]
    }
   ],
   "source": [
    "!unzip mlboot_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2673964\r\n",
      "drwx------ 11 root root       4096 Jul 14 18:11 .\r\n",
      "drwxr-xr-x 23 root root       4096 Jul 14 17:12 ..\r\n",
      "-rw-------  1 root root        487 Jul 14 18:00 .bash_history\r\n",
      "-rw-r--r--  1 root root       3106 Apr  9 11:10 .bashrc\r\n",
      "drwx------  4 root root       4096 Jul 14 17:34 .cache\r\n",
      "-rw-r--r--  1 root root          0 Jul 14 17:12 .cloud-locale-test.skip\r\n",
      "drwx------  3 root root       4096 Jul 14 17:34 .config\r\n",
      "drwxr-xr-x  2 root root       4096 Jul 14 17:23 .ipynb_checkpoints\r\n",
      "drwxr-xr-x  5 root root       4096 Jul 14 17:22 .ipython\r\n",
      "drwxr-xr-x  2 root root       4096 Jul 14 18:05 .jupyter\r\n",
      "drwx------  3 root root       4096 Jul 14 17:19 .local\r\n",
      "-rw-r--r--  1 root root        148 Aug 17  2015 .profile\r\n",
      "drwx------  2 root root       4096 Jul 14 17:12 .ssh\r\n",
      "drwxrwxr-x  3 root root       4096 Jun 25 13:57 __MACOSX\r\n",
      "-rw-r--r--  1 root root      10164 Jul 14 18:11 mlboot.ipynb\r\n",
      "drwx------  2 root root       4096 Jun 25 13:56 mlboot_dataset\r\n",
      "-rw-r--r--  1 root root 2738062403 Jun 25 14:10 mlboot_dataset.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import lightgbm as lgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_table('mlboot_dataset/mlboot_train_answers.tsv.gz')\n",
    "testdf = pd.read_table('mlboot_dataset/mlboot_test.tsv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19528598"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunksize = 19528597 // 1 + 1\n",
    "chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-22 11:18:53.292670 start reading\n",
      "2018-07-22 11:22:14.419286 read\n",
      "2018-07-22 11:22:14.419466  Iteration:  1\n",
      "2018-07-22 11:22:36.646016 entering train/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-22 11:22:59.677548 train/test created\n",
      "2018-07-22 11:26:10.550100 entering tfidf\n",
      "2018-07-22 11:43:21.597805 2 tfidf done\n",
      "2018-07-22 12:47:20.073626 3 tfidf done\n",
      "2018-07-22 12:49:33.004803 hstack\n",
      "TRAIN: [ 1287435  1287436  1287437 ... 12874342 12874343 12874344] \n",
      "TEST: [      0       1       2 ... 1287432 1287433 1287434]\n",
      "2018-07-22 12:52:22.289023  FOLD  1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.566326\n",
      "[10]\tvalid_0's auc: 0.574065\n",
      "[15]\tvalid_0's auc: 0.577702\n",
      "[20]\tvalid_0's auc: 0.580134\n",
      "[25]\tvalid_0's auc: 0.582619\n",
      "[30]\tvalid_0's auc: 0.583602\n",
      "[35]\tvalid_0's auc: 0.58529\n",
      "[40]\tvalid_0's auc: 0.585909\n",
      "[45]\tvalid_0's auc: 0.587424\n",
      "[50]\tvalid_0's auc: 0.58871\n",
      "[55]\tvalid_0's auc: 0.589444\n",
      "[60]\tvalid_0's auc: 0.590201\n",
      "[65]\tvalid_0's auc: 0.590686\n",
      "[70]\tvalid_0's auc: 0.590623\n",
      "[75]\tvalid_0's auc: 0.590928\n",
      "[80]\tvalid_0's auc: 0.591338\n",
      "[85]\tvalid_0's auc: 0.591784\n",
      "[90]\tvalid_0's auc: 0.592109\n",
      "[95]\tvalid_0's auc: 0.59238\n",
      "[100]\tvalid_0's auc: 0.592615\n",
      "[105]\tvalid_0's auc: 0.592713\n",
      "[110]\tvalid_0's auc: 0.593125\n",
      "[115]\tvalid_0's auc: 0.593497\n",
      "[120]\tvalid_0's auc: 0.593991\n",
      "[125]\tvalid_0's auc: 0.594035\n",
      "[130]\tvalid_0's auc: 0.594206\n",
      "[135]\tvalid_0's auc: 0.594252\n",
      "[140]\tvalid_0's auc: 0.594622\n",
      "[145]\tvalid_0's auc: 0.594759\n",
      "[150]\tvalid_0's auc: 0.595026\n",
      "[155]\tvalid_0's auc: 0.595302\n",
      "[160]\tvalid_0's auc: 0.595427\n",
      "[165]\tvalid_0's auc: 0.595455\n",
      "[170]\tvalid_0's auc: 0.595576\n",
      "[175]\tvalid_0's auc: 0.595793\n",
      "[180]\tvalid_0's auc: 0.595977\n",
      "[185]\tvalid_0's auc: 0.596293\n",
      "[190]\tvalid_0's auc: 0.596466\n",
      "[195]\tvalid_0's auc: 0.596464\n",
      "[200]\tvalid_0's auc: 0.596574\n",
      "[205]\tvalid_0's auc: 0.596925\n",
      "[210]\tvalid_0's auc: 0.596856\n",
      "[215]\tvalid_0's auc: 0.596805\n",
      "[220]\tvalid_0's auc: 0.596783\n",
      "[225]\tvalid_0's auc: 0.596863\n",
      "[230]\tvalid_0's auc: 0.596933\n",
      "[235]\tvalid_0's auc: 0.596945\n",
      "[240]\tvalid_0's auc: 0.596954\n",
      "[245]\tvalid_0's auc: 0.596975\n",
      "[250]\tvalid_0's auc: 0.597059\n",
      "[255]\tvalid_0's auc: 0.596995\n",
      "[260]\tvalid_0's auc: 0.596953\n",
      "[265]\tvalid_0's auc: 0.597003\n",
      "[270]\tvalid_0's auc: 0.597105\n",
      "[275]\tvalid_0's auc: 0.597202\n",
      "[280]\tvalid_0's auc: 0.597308\n",
      "[285]\tvalid_0's auc: 0.597106\n",
      "[290]\tvalid_0's auc: 0.597129\n",
      "[295]\tvalid_0's auc: 0.597318\n",
      "[300]\tvalid_0's auc: 0.597574\n",
      "[305]\tvalid_0's auc: 0.597644\n",
      "[310]\tvalid_0's auc: 0.597698\n",
      "[315]\tvalid_0's auc: 0.597432\n",
      "[320]\tvalid_0's auc: 0.597373\n",
      "[325]\tvalid_0's auc: 0.597323\n",
      "[330]\tvalid_0's auc: 0.597393\n",
      "[335]\tvalid_0's auc: 0.597862\n",
      "[340]\tvalid_0's auc: 0.597815\n",
      "[345]\tvalid_0's auc: 0.597936\n",
      "[350]\tvalid_0's auc: 0.598035\n",
      "[355]\tvalid_0's auc: 0.598118\n",
      "[360]\tvalid_0's auc: 0.598044\n",
      "[365]\tvalid_0's auc: 0.59805\n",
      "[370]\tvalid_0's auc: 0.598092\n",
      "[375]\tvalid_0's auc: 0.59796\n",
      "[380]\tvalid_0's auc: 0.597967\n",
      "[385]\tvalid_0's auc: 0.598071\n",
      "[390]\tvalid_0's auc: 0.597993\n",
      "[395]\tvalid_0's auc: 0.597998\n",
      "[400]\tvalid_0's auc: 0.598106\n",
      "[405]\tvalid_0's auc: 0.597888\n",
      "[410]\tvalid_0's auc: 0.597914\n",
      "[415]\tvalid_0's auc: 0.597975\n",
      "[420]\tvalid_0's auc: 0.598017\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's auc: 0.598136\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [1287435 1287436 1287437 ... 2574867 2574868 2574869]\n",
      "2018-07-22 13:16:09.230491  FOLD  2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.574018\n",
      "[10]\tvalid_0's auc: 0.57679\n",
      "[15]\tvalid_0's auc: 0.583533\n",
      "[20]\tvalid_0's auc: 0.585269\n",
      "[25]\tvalid_0's auc: 0.583718\n",
      "[30]\tvalid_0's auc: 0.586814\n",
      "[35]\tvalid_0's auc: 0.587883\n",
      "[40]\tvalid_0's auc: 0.588724\n",
      "[45]\tvalid_0's auc: 0.590468\n",
      "[50]\tvalid_0's auc: 0.591286\n",
      "[55]\tvalid_0's auc: 0.592166\n",
      "[60]\tvalid_0's auc: 0.592865\n",
      "[65]\tvalid_0's auc: 0.593346\n",
      "[70]\tvalid_0's auc: 0.594206\n",
      "[75]\tvalid_0's auc: 0.594285\n",
      "[80]\tvalid_0's auc: 0.594911\n",
      "[85]\tvalid_0's auc: 0.595546\n",
      "[90]\tvalid_0's auc: 0.595694\n",
      "[95]\tvalid_0's auc: 0.596032\n",
      "[100]\tvalid_0's auc: 0.595961\n",
      "[105]\tvalid_0's auc: 0.59602\n",
      "[110]\tvalid_0's auc: 0.595872\n",
      "[115]\tvalid_0's auc: 0.596161\n",
      "[120]\tvalid_0's auc: 0.596303\n",
      "[125]\tvalid_0's auc: 0.596126\n",
      "[130]\tvalid_0's auc: 0.596197\n",
      "[135]\tvalid_0's auc: 0.596423\n",
      "[140]\tvalid_0's auc: 0.596326\n",
      "[145]\tvalid_0's auc: 0.596568\n",
      "[150]\tvalid_0's auc: 0.596554\n",
      "[155]\tvalid_0's auc: 0.596639\n",
      "[160]\tvalid_0's auc: 0.596791\n",
      "[165]\tvalid_0's auc: 0.596951\n",
      "[170]\tvalid_0's auc: 0.596867\n",
      "[175]\tvalid_0's auc: 0.596783\n",
      "[180]\tvalid_0's auc: 0.596886\n",
      "[185]\tvalid_0's auc: 0.597036\n",
      "[190]\tvalid_0's auc: 0.59724\n",
      "[195]\tvalid_0's auc: 0.597375\n",
      "[200]\tvalid_0's auc: 0.597425\n",
      "[205]\tvalid_0's auc: 0.597426\n",
      "[210]\tvalid_0's auc: 0.59761\n",
      "[215]\tvalid_0's auc: 0.59757\n",
      "[220]\tvalid_0's auc: 0.597543\n",
      "[225]\tvalid_0's auc: 0.597583\n",
      "[230]\tvalid_0's auc: 0.597428\n",
      "[235]\tvalid_0's auc: 0.597302\n",
      "[240]\tvalid_0's auc: 0.597486\n",
      "[245]\tvalid_0's auc: 0.597688\n",
      "[250]\tvalid_0's auc: 0.597823\n",
      "[255]\tvalid_0's auc: 0.597873\n",
      "[260]\tvalid_0's auc: 0.597954\n",
      "[265]\tvalid_0's auc: 0.597977\n",
      "[270]\tvalid_0's auc: 0.598447\n",
      "[275]\tvalid_0's auc: 0.598348\n",
      "[280]\tvalid_0's auc: 0.598396\n",
      "[285]\tvalid_0's auc: 0.598416\n",
      "[290]\tvalid_0's auc: 0.598548\n",
      "[295]\tvalid_0's auc: 0.598534\n",
      "[300]\tvalid_0's auc: 0.598596\n",
      "[305]\tvalid_0's auc: 0.598539\n",
      "[310]\tvalid_0's auc: 0.598436\n",
      "[315]\tvalid_0's auc: 0.598435\n",
      "[320]\tvalid_0's auc: 0.598494\n",
      "[325]\tvalid_0's auc: 0.598567\n",
      "[330]\tvalid_0's auc: 0.598706\n",
      "[335]\tvalid_0's auc: 0.598691\n",
      "[340]\tvalid_0's auc: 0.598561\n",
      "[345]\tvalid_0's auc: 0.598394\n",
      "[350]\tvalid_0's auc: 0.598266\n",
      "[355]\tvalid_0's auc: 0.59823\n",
      "[360]\tvalid_0's auc: 0.598118\n",
      "[365]\tvalid_0's auc: 0.598066\n",
      "[370]\tvalid_0's auc: 0.598116\n",
      "[375]\tvalid_0's auc: 0.59834\n",
      "[380]\tvalid_0's auc: 0.598376\n",
      "[385]\tvalid_0's auc: 0.59838\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid_0's auc: 0.59872\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [2574870 2574871 2574872 ... 3862302 3862303 3862304]\n",
      "2018-07-22 13:39:18.587805  FOLD  3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.583975\n",
      "[10]\tvalid_0's auc: 0.589211\n",
      "[15]\tvalid_0's auc: 0.591885\n",
      "[20]\tvalid_0's auc: 0.593263\n",
      "[25]\tvalid_0's auc: 0.594713\n",
      "[30]\tvalid_0's auc: 0.596245\n",
      "[35]\tvalid_0's auc: 0.597364\n",
      "[40]\tvalid_0's auc: 0.599073\n",
      "[45]\tvalid_0's auc: 0.599937\n",
      "[50]\tvalid_0's auc: 0.600944\n",
      "[55]\tvalid_0's auc: 0.602009\n",
      "[60]\tvalid_0's auc: 0.602678\n",
      "[65]\tvalid_0's auc: 0.602489\n",
      "[70]\tvalid_0's auc: 0.6032\n",
      "[75]\tvalid_0's auc: 0.60365\n",
      "[80]\tvalid_0's auc: 0.603991\n",
      "[85]\tvalid_0's auc: 0.604122\n",
      "[90]\tvalid_0's auc: 0.60434\n",
      "[95]\tvalid_0's auc: 0.604485\n",
      "[100]\tvalid_0's auc: 0.604643\n",
      "[105]\tvalid_0's auc: 0.604566\n",
      "[110]\tvalid_0's auc: 0.604845\n",
      "[115]\tvalid_0's auc: 0.605075\n",
      "[120]\tvalid_0's auc: 0.60527\n",
      "[125]\tvalid_0's auc: 0.605439\n",
      "[130]\tvalid_0's auc: 0.605699\n",
      "[135]\tvalid_0's auc: 0.605862\n",
      "[140]\tvalid_0's auc: 0.605857\n",
      "[145]\tvalid_0's auc: 0.606003\n",
      "[150]\tvalid_0's auc: 0.606166\n",
      "[155]\tvalid_0's auc: 0.606147\n",
      "[160]\tvalid_0's auc: 0.606238\n",
      "[165]\tvalid_0's auc: 0.606349\n",
      "[170]\tvalid_0's auc: 0.606534\n",
      "[175]\tvalid_0's auc: 0.606664\n",
      "[180]\tvalid_0's auc: 0.606735\n",
      "[185]\tvalid_0's auc: 0.606546\n",
      "[190]\tvalid_0's auc: 0.606613\n",
      "[195]\tvalid_0's auc: 0.606568\n",
      "[200]\tvalid_0's auc: 0.606605\n",
      "[205]\tvalid_0's auc: 0.606797\n",
      "[210]\tvalid_0's auc: 0.60684\n",
      "[215]\tvalid_0's auc: 0.606705\n",
      "[220]\tvalid_0's auc: 0.606865\n",
      "[225]\tvalid_0's auc: 0.607\n",
      "[230]\tvalid_0's auc: 0.606982\n",
      "[235]\tvalid_0's auc: 0.606979\n",
      "[240]\tvalid_0's auc: 0.607104\n",
      "[245]\tvalid_0's auc: 0.606995\n",
      "[250]\tvalid_0's auc: 0.607068\n",
      "[255]\tvalid_0's auc: 0.607203\n",
      "[260]\tvalid_0's auc: 0.607296\n",
      "[265]\tvalid_0's auc: 0.60731\n",
      "[270]\tvalid_0's auc: 0.607371\n",
      "[275]\tvalid_0's auc: 0.607545\n",
      "[280]\tvalid_0's auc: 0.607521\n",
      "[285]\tvalid_0's auc: 0.607512\n",
      "[290]\tvalid_0's auc: 0.607722\n",
      "[295]\tvalid_0's auc: 0.607667\n",
      "[300]\tvalid_0's auc: 0.607687\n",
      "[305]\tvalid_0's auc: 0.607571\n",
      "[310]\tvalid_0's auc: 0.607539\n",
      "[315]\tvalid_0's auc: 0.607482\n",
      "[320]\tvalid_0's auc: 0.607486\n",
      "[325]\tvalid_0's auc: 0.607436\n",
      "[330]\tvalid_0's auc: 0.60753\n",
      "[335]\tvalid_0's auc: 0.607614\n",
      "[340]\tvalid_0's auc: 0.607657\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's auc: 0.607752\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [3862305 3862306 3862307 ... 5149737 5149738 5149739]\n",
      "2018-07-22 14:21:28.312560  FOLD  4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.591626\n",
      "[10]\tvalid_0's auc: 0.59187\n",
      "[15]\tvalid_0's auc: 0.596435\n",
      "[20]\tvalid_0's auc: 0.597785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tvalid_0's auc: 0.597857\n",
      "[30]\tvalid_0's auc: 0.599248\n",
      "[35]\tvalid_0's auc: 0.599379\n",
      "[40]\tvalid_0's auc: 0.600077\n",
      "[45]\tvalid_0's auc: 0.60102\n",
      "[50]\tvalid_0's auc: 0.601517\n",
      "[55]\tvalid_0's auc: 0.602162\n",
      "[60]\tvalid_0's auc: 0.602562\n",
      "[65]\tvalid_0's auc: 0.602734\n",
      "[70]\tvalid_0's auc: 0.603221\n",
      "[75]\tvalid_0's auc: 0.603468\n",
      "[80]\tvalid_0's auc: 0.603519\n",
      "[85]\tvalid_0's auc: 0.603816\n",
      "[90]\tvalid_0's auc: 0.603968\n",
      "[95]\tvalid_0's auc: 0.6043\n",
      "[100]\tvalid_0's auc: 0.604501\n",
      "[105]\tvalid_0's auc: 0.604554\n",
      "[110]\tvalid_0's auc: 0.604912\n",
      "[115]\tvalid_0's auc: 0.604865\n",
      "[120]\tvalid_0's auc: 0.605034\n",
      "[125]\tvalid_0's auc: 0.60556\n",
      "[130]\tvalid_0's auc: 0.60564\n",
      "[135]\tvalid_0's auc: 0.605725\n",
      "[140]\tvalid_0's auc: 0.605646\n",
      "[145]\tvalid_0's auc: 0.605876\n",
      "[150]\tvalid_0's auc: 0.605949\n",
      "[155]\tvalid_0's auc: 0.606056\n",
      "[160]\tvalid_0's auc: 0.606062\n",
      "[165]\tvalid_0's auc: 0.606189\n",
      "[170]\tvalid_0's auc: 0.606154\n",
      "[175]\tvalid_0's auc: 0.606274\n",
      "[180]\tvalid_0's auc: 0.606435\n",
      "[185]\tvalid_0's auc: 0.606137\n",
      "[190]\tvalid_0's auc: 0.60612\n",
      "[195]\tvalid_0's auc: 0.606035\n",
      "[200]\tvalid_0's auc: 0.605927\n",
      "[205]\tvalid_0's auc: 0.606015\n",
      "[210]\tvalid_0's auc: 0.606124\n",
      "[215]\tvalid_0's auc: 0.606267\n",
      "[220]\tvalid_0's auc: 0.606162\n",
      "[225]\tvalid_0's auc: 0.606467\n",
      "[230]\tvalid_0's auc: 0.606407\n",
      "[235]\tvalid_0's auc: 0.606528\n",
      "[240]\tvalid_0's auc: 0.606631\n",
      "[245]\tvalid_0's auc: 0.606657\n",
      "[250]\tvalid_0's auc: 0.606657\n",
      "[255]\tvalid_0's auc: 0.606764\n",
      "[260]\tvalid_0's auc: 0.606953\n",
      "[265]\tvalid_0's auc: 0.607016\n",
      "[270]\tvalid_0's auc: 0.607124\n",
      "[275]\tvalid_0's auc: 0.607178\n",
      "[280]\tvalid_0's auc: 0.607248\n",
      "[285]\tvalid_0's auc: 0.607277\n",
      "[290]\tvalid_0's auc: 0.607231\n",
      "[295]\tvalid_0's auc: 0.607269\n",
      "[300]\tvalid_0's auc: 0.607228\n",
      "[305]\tvalid_0's auc: 0.607048\n",
      "[310]\tvalid_0's auc: 0.607234\n",
      "[315]\tvalid_0's auc: 0.607234\n",
      "[320]\tvalid_0's auc: 0.60721\n",
      "[325]\tvalid_0's auc: 0.607109\n",
      "[330]\tvalid_0's auc: 0.607136\n",
      "[335]\tvalid_0's auc: 0.607245\n",
      "[340]\tvalid_0's auc: 0.607159\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid_0's auc: 0.607325\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [5149740 5149741 5149742 ... 6437172 6437173 6437174]\n",
      "2018-07-22 15:04:11.626467  FOLD  5\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.585043\n",
      "[10]\tvalid_0's auc: 0.5925\n",
      "[15]\tvalid_0's auc: 0.593924\n",
      "[20]\tvalid_0's auc: 0.596665\n",
      "[25]\tvalid_0's auc: 0.597252\n",
      "[30]\tvalid_0's auc: 0.599403\n",
      "[35]\tvalid_0's auc: 0.600681\n",
      "[40]\tvalid_0's auc: 0.601743\n",
      "[45]\tvalid_0's auc: 0.602476\n",
      "[50]\tvalid_0's auc: 0.60294\n",
      "[55]\tvalid_0's auc: 0.603677\n",
      "[60]\tvalid_0's auc: 0.604018\n",
      "[65]\tvalid_0's auc: 0.60458\n",
      "[70]\tvalid_0's auc: 0.604588\n",
      "[75]\tvalid_0's auc: 0.604623\n",
      "[80]\tvalid_0's auc: 0.604737\n",
      "[85]\tvalid_0's auc: 0.605203\n",
      "[90]\tvalid_0's auc: 0.605502\n",
      "[95]\tvalid_0's auc: 0.605865\n",
      "[100]\tvalid_0's auc: 0.60594\n",
      "[105]\tvalid_0's auc: 0.605861\n",
      "[110]\tvalid_0's auc: 0.605967\n",
      "[115]\tvalid_0's auc: 0.60576\n",
      "[120]\tvalid_0's auc: 0.605973\n",
      "[125]\tvalid_0's auc: 0.606348\n",
      "[130]\tvalid_0's auc: 0.606367\n",
      "[135]\tvalid_0's auc: 0.60658\n",
      "[140]\tvalid_0's auc: 0.606703\n",
      "[145]\tvalid_0's auc: 0.606469\n",
      "[150]\tvalid_0's auc: 0.606454\n",
      "[155]\tvalid_0's auc: 0.606775\n",
      "[160]\tvalid_0's auc: 0.606706\n",
      "[165]\tvalid_0's auc: 0.606909\n",
      "[170]\tvalid_0's auc: 0.607237\n",
      "[175]\tvalid_0's auc: 0.607279\n",
      "[180]\tvalid_0's auc: 0.607273\n",
      "[185]\tvalid_0's auc: 0.607416\n",
      "[190]\tvalid_0's auc: 0.607454\n",
      "[195]\tvalid_0's auc: 0.607717\n",
      "[200]\tvalid_0's auc: 0.607795\n",
      "[205]\tvalid_0's auc: 0.607957\n",
      "[210]\tvalid_0's auc: 0.607957\n",
      "[215]\tvalid_0's auc: 0.607891\n",
      "[220]\tvalid_0's auc: 0.60808\n",
      "[225]\tvalid_0's auc: 0.608169\n",
      "[230]\tvalid_0's auc: 0.60821\n",
      "[235]\tvalid_0's auc: 0.608221\n",
      "[240]\tvalid_0's auc: 0.608406\n",
      "[245]\tvalid_0's auc: 0.608334\n",
      "[250]\tvalid_0's auc: 0.608372\n",
      "[255]\tvalid_0's auc: 0.608405\n",
      "[260]\tvalid_0's auc: 0.608399\n",
      "[265]\tvalid_0's auc: 0.608511\n",
      "[270]\tvalid_0's auc: 0.608534\n",
      "[275]\tvalid_0's auc: 0.60858\n",
      "[280]\tvalid_0's auc: 0.608595\n",
      "[285]\tvalid_0's auc: 0.608659\n",
      "[290]\tvalid_0's auc: 0.608522\n",
      "[295]\tvalid_0's auc: 0.608533\n",
      "[300]\tvalid_0's auc: 0.608614\n",
      "[305]\tvalid_0's auc: 0.608603\n",
      "[310]\tvalid_0's auc: 0.608668\n",
      "[315]\tvalid_0's auc: 0.608732\n",
      "[320]\tvalid_0's auc: 0.608681\n",
      "[325]\tvalid_0's auc: 0.608732\n",
      "[330]\tvalid_0's auc: 0.608764\n",
      "[335]\tvalid_0's auc: 0.608598\n",
      "[340]\tvalid_0's auc: 0.60863\n",
      "[345]\tvalid_0's auc: 0.608489\n",
      "[350]\tvalid_0's auc: 0.608465\n",
      "[355]\tvalid_0's auc: 0.608434\n",
      "[360]\tvalid_0's auc: 0.608383\n",
      "[365]\tvalid_0's auc: 0.608295\n",
      "[370]\tvalid_0's auc: 0.608285\n",
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's auc: 0.608783\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [6437175 6437176 6437177 ... 7724606 7724607 7724608]\n",
      "2018-07-22 15:50:12.252837  FOLD  6\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.581435\n",
      "[10]\tvalid_0's auc: 0.585896\n",
      "[15]\tvalid_0's auc: 0.589147\n",
      "[20]\tvalid_0's auc: 0.591326\n",
      "[25]\tvalid_0's auc: 0.591221\n",
      "[30]\tvalid_0's auc: 0.592638\n",
      "[35]\tvalid_0's auc: 0.594379\n",
      "[40]\tvalid_0's auc: 0.596233\n",
      "[45]\tvalid_0's auc: 0.597669\n",
      "[50]\tvalid_0's auc: 0.598728\n",
      "[55]\tvalid_0's auc: 0.59933\n",
      "[60]\tvalid_0's auc: 0.600235\n",
      "[65]\tvalid_0's auc: 0.601043\n",
      "[70]\tvalid_0's auc: 0.601771\n",
      "[75]\tvalid_0's auc: 0.601966\n",
      "[80]\tvalid_0's auc: 0.60253\n",
      "[85]\tvalid_0's auc: 0.602939\n",
      "[90]\tvalid_0's auc: 0.602776\n",
      "[95]\tvalid_0's auc: 0.602967\n",
      "[100]\tvalid_0's auc: 0.60339\n",
      "[105]\tvalid_0's auc: 0.603721\n",
      "[110]\tvalid_0's auc: 0.604049\n",
      "[115]\tvalid_0's auc: 0.60415\n",
      "[120]\tvalid_0's auc: 0.604197\n",
      "[125]\tvalid_0's auc: 0.604399\n",
      "[130]\tvalid_0's auc: 0.604716\n",
      "[135]\tvalid_0's auc: 0.604811\n",
      "[140]\tvalid_0's auc: 0.604964\n",
      "[145]\tvalid_0's auc: 0.604949\n",
      "[150]\tvalid_0's auc: 0.605245\n",
      "[155]\tvalid_0's auc: 0.6053\n",
      "[160]\tvalid_0's auc: 0.6048\n",
      "[165]\tvalid_0's auc: 0.604788\n",
      "[170]\tvalid_0's auc: 0.604866\n",
      "[175]\tvalid_0's auc: 0.604915\n",
      "[180]\tvalid_0's auc: 0.605072\n",
      "[185]\tvalid_0's auc: 0.605219\n",
      "[190]\tvalid_0's auc: 0.605115\n",
      "[195]\tvalid_0's auc: 0.605178\n",
      "[200]\tvalid_0's auc: 0.605248\n",
      "[205]\tvalid_0's auc: 0.605385\n",
      "[210]\tvalid_0's auc: 0.605516\n",
      "[215]\tvalid_0's auc: 0.605614\n",
      "[220]\tvalid_0's auc: 0.605689\n",
      "[225]\tvalid_0's auc: 0.605674\n",
      "[230]\tvalid_0's auc: 0.605654\n",
      "[235]\tvalid_0's auc: 0.605748\n",
      "[240]\tvalid_0's auc: 0.605681\n",
      "[245]\tvalid_0's auc: 0.605674\n",
      "[250]\tvalid_0's auc: 0.605607\n",
      "[255]\tvalid_0's auc: 0.605852\n",
      "[260]\tvalid_0's auc: 0.605848\n",
      "[265]\tvalid_0's auc: 0.605938\n",
      "[270]\tvalid_0's auc: 0.606065\n",
      "[275]\tvalid_0's auc: 0.606057\n",
      "[280]\tvalid_0's auc: 0.606111\n",
      "[285]\tvalid_0's auc: 0.606203\n",
      "[290]\tvalid_0's auc: 0.606293\n",
      "[295]\tvalid_0's auc: 0.60642\n",
      "[300]\tvalid_0's auc: 0.606435\n",
      "[305]\tvalid_0's auc: 0.606458\n",
      "[310]\tvalid_0's auc: 0.606485\n",
      "[315]\tvalid_0's auc: 0.606826\n",
      "[320]\tvalid_0's auc: 0.606965\n",
      "[325]\tvalid_0's auc: 0.607078\n",
      "[330]\tvalid_0's auc: 0.607135\n",
      "[335]\tvalid_0's auc: 0.607216\n",
      "[340]\tvalid_0's auc: 0.607295\n",
      "[345]\tvalid_0's auc: 0.607225\n",
      "[350]\tvalid_0's auc: 0.607237\n",
      "[355]\tvalid_0's auc: 0.607324\n",
      "[360]\tvalid_0's auc: 0.607319\n",
      "[365]\tvalid_0's auc: 0.60729\n",
      "[370]\tvalid_0's auc: 0.607414\n",
      "[375]\tvalid_0's auc: 0.607511\n",
      "[380]\tvalid_0's auc: 0.607527\n",
      "[385]\tvalid_0's auc: 0.607556\n",
      "[390]\tvalid_0's auc: 0.607573\n",
      "[395]\tvalid_0's auc: 0.607552\n",
      "[400]\tvalid_0's auc: 0.607545\n",
      "[405]\tvalid_0's auc: 0.607552\n",
      "[410]\tvalid_0's auc: 0.60757\n",
      "[415]\tvalid_0's auc: 0.607637\n",
      "[420]\tvalid_0's auc: 0.60766\n",
      "[425]\tvalid_0's auc: 0.607613\n",
      "[430]\tvalid_0's auc: 0.608006\n",
      "[435]\tvalid_0's auc: 0.607925\n",
      "[440]\tvalid_0's auc: 0.607823\n",
      "[445]\tvalid_0's auc: 0.607635\n",
      "[450]\tvalid_0's auc: 0.607679\n",
      "[455]\tvalid_0's auc: 0.607687\n",
      "[460]\tvalid_0's auc: 0.607756\n",
      "[465]\tvalid_0's auc: 0.607817\n",
      "[470]\tvalid_0's auc: 0.607649\n",
      "[475]\tvalid_0's auc: 0.607748\n",
      "[480]\tvalid_0's auc: 0.607604\n",
      "Early stopping, best iteration is:\n",
      "[431]\tvalid_0's auc: 0.608047\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [7724609 7724610 7724611 ... 9012040 9012041 9012042]\n",
      "2018-07-22 16:45:22.948035  FOLD  7\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.584406\n",
      "[10]\tvalid_0's auc: 0.584067\n",
      "[15]\tvalid_0's auc: 0.591637\n",
      "[20]\tvalid_0's auc: 0.591095\n",
      "[25]\tvalid_0's auc: 0.591726\n",
      "[30]\tvalid_0's auc: 0.59264\n",
      "[35]\tvalid_0's auc: 0.594371\n",
      "[40]\tvalid_0's auc: 0.596755\n",
      "[45]\tvalid_0's auc: 0.598321\n",
      "[50]\tvalid_0's auc: 0.600075\n",
      "[55]\tvalid_0's auc: 0.601118\n",
      "[60]\tvalid_0's auc: 0.601514\n",
      "[65]\tvalid_0's auc: 0.602025\n",
      "[70]\tvalid_0's auc: 0.602866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75]\tvalid_0's auc: 0.602914\n",
      "[80]\tvalid_0's auc: 0.603154\n",
      "[85]\tvalid_0's auc: 0.603387\n",
      "[90]\tvalid_0's auc: 0.60372\n",
      "[95]\tvalid_0's auc: 0.604032\n",
      "[100]\tvalid_0's auc: 0.604384\n",
      "[105]\tvalid_0's auc: 0.604501\n",
      "[110]\tvalid_0's auc: 0.604532\n",
      "[115]\tvalid_0's auc: 0.604555\n",
      "[120]\tvalid_0's auc: 0.604624\n",
      "[125]\tvalid_0's auc: 0.604701\n",
      "[130]\tvalid_0's auc: 0.60482\n",
      "[135]\tvalid_0's auc: 0.605008\n",
      "[140]\tvalid_0's auc: 0.605033\n",
      "[145]\tvalid_0's auc: 0.605146\n",
      "[150]\tvalid_0's auc: 0.605099\n",
      "[155]\tvalid_0's auc: 0.605065\n",
      "[160]\tvalid_0's auc: 0.605245\n",
      "[165]\tvalid_0's auc: 0.605448\n",
      "[170]\tvalid_0's auc: 0.605654\n",
      "[175]\tvalid_0's auc: 0.605603\n",
      "[180]\tvalid_0's auc: 0.605788\n",
      "[185]\tvalid_0's auc: 0.605735\n",
      "[190]\tvalid_0's auc: 0.605699\n",
      "[195]\tvalid_0's auc: 0.605526\n",
      "[200]\tvalid_0's auc: 0.605385\n",
      "[205]\tvalid_0's auc: 0.605536\n",
      "[210]\tvalid_0's auc: 0.605717\n",
      "[215]\tvalid_0's auc: 0.605738\n",
      "[220]\tvalid_0's auc: 0.605685\n",
      "[225]\tvalid_0's auc: 0.60599\n",
      "[230]\tvalid_0's auc: 0.605994\n",
      "[235]\tvalid_0's auc: 0.606002\n",
      "[240]\tvalid_0's auc: 0.605929\n",
      "[245]\tvalid_0's auc: 0.605886\n",
      "[250]\tvalid_0's auc: 0.605957\n",
      "[255]\tvalid_0's auc: 0.605922\n",
      "[260]\tvalid_0's auc: 0.605804\n",
      "[265]\tvalid_0's auc: 0.605734\n",
      "[270]\tvalid_0's auc: 0.60576\n",
      "[275]\tvalid_0's auc: 0.60566\n",
      "[280]\tvalid_0's auc: 0.605826\n",
      "[285]\tvalid_0's auc: 0.605781\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's auc: 0.606109\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [ 9012043  9012044  9012045 ... 10299474 10299475 10299476]\n",
      "2018-07-22 17:25:11.070112  FOLD  8\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.581297\n",
      "[10]\tvalid_0's auc: 0.58673\n",
      "[15]\tvalid_0's auc: 0.588493\n",
      "[20]\tvalid_0's auc: 0.590367\n",
      "[25]\tvalid_0's auc: 0.589393\n",
      "[30]\tvalid_0's auc: 0.589646\n",
      "[35]\tvalid_0's auc: 0.590587\n",
      "[40]\tvalid_0's auc: 0.592486\n",
      "[45]\tvalid_0's auc: 0.593111\n",
      "[50]\tvalid_0's auc: 0.594751\n",
      "[55]\tvalid_0's auc: 0.595441\n",
      "[60]\tvalid_0's auc: 0.59594\n",
      "[65]\tvalid_0's auc: 0.596644\n",
      "[70]\tvalid_0's auc: 0.597206\n",
      "[75]\tvalid_0's auc: 0.59759\n",
      "[80]\tvalid_0's auc: 0.597898\n",
      "[85]\tvalid_0's auc: 0.598088\n",
      "[90]\tvalid_0's auc: 0.598435\n",
      "[95]\tvalid_0's auc: 0.599002\n",
      "[100]\tvalid_0's auc: 0.59943\n",
      "[105]\tvalid_0's auc: 0.599629\n",
      "[110]\tvalid_0's auc: 0.599996\n",
      "[115]\tvalid_0's auc: 0.600238\n",
      "[120]\tvalid_0's auc: 0.600188\n",
      "[125]\tvalid_0's auc: 0.600515\n",
      "[130]\tvalid_0's auc: 0.600881\n",
      "[135]\tvalid_0's auc: 0.6013\n",
      "[140]\tvalid_0's auc: 0.601562\n",
      "[145]\tvalid_0's auc: 0.601572\n",
      "[150]\tvalid_0's auc: 0.601469\n",
      "[155]\tvalid_0's auc: 0.601851\n",
      "[160]\tvalid_0's auc: 0.602108\n",
      "[165]\tvalid_0's auc: 0.602205\n",
      "[170]\tvalid_0's auc: 0.602369\n",
      "[175]\tvalid_0's auc: 0.602619\n",
      "[180]\tvalid_0's auc: 0.602764\n",
      "[185]\tvalid_0's auc: 0.602632\n",
      "[190]\tvalid_0's auc: 0.60278\n",
      "[195]\tvalid_0's auc: 0.603519\n",
      "[200]\tvalid_0's auc: 0.603572\n",
      "[205]\tvalid_0's auc: 0.603866\n",
      "[210]\tvalid_0's auc: 0.603645\n",
      "[215]\tvalid_0's auc: 0.603712\n",
      "[220]\tvalid_0's auc: 0.603643\n",
      "[225]\tvalid_0's auc: 0.603686\n",
      "[230]\tvalid_0's auc: 0.603646\n",
      "[235]\tvalid_0's auc: 0.603967\n",
      "[240]\tvalid_0's auc: 0.604051\n",
      "[245]\tvalid_0's auc: 0.604051\n",
      "[250]\tvalid_0's auc: 0.604166\n",
      "[255]\tvalid_0's auc: 0.604338\n",
      "[260]\tvalid_0's auc: 0.604338\n",
      "[265]\tvalid_0's auc: 0.604171\n",
      "[270]\tvalid_0's auc: 0.604169\n",
      "[275]\tvalid_0's auc: 0.604271\n",
      "[280]\tvalid_0's auc: 0.604197\n",
      "[285]\tvalid_0's auc: 0.604403\n",
      "[290]\tvalid_0's auc: 0.604572\n",
      "[295]\tvalid_0's auc: 0.604797\n",
      "[300]\tvalid_0's auc: 0.604778\n",
      "[305]\tvalid_0's auc: 0.604887\n",
      "[310]\tvalid_0's auc: 0.604865\n",
      "[315]\tvalid_0's auc: 0.604933\n",
      "[320]\tvalid_0's auc: 0.604878\n",
      "[325]\tvalid_0's auc: 0.604672\n",
      "[330]\tvalid_0's auc: 0.604652\n",
      "[335]\tvalid_0's auc: 0.604576\n",
      "[340]\tvalid_0's auc: 0.604567\n",
      "[345]\tvalid_0's auc: 0.604664\n",
      "[350]\tvalid_0's auc: 0.604644\n",
      "[355]\tvalid_0's auc: 0.604618\n",
      "[360]\tvalid_0's auc: 0.604356\n",
      "[365]\tvalid_0's auc: 0.604423\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid_0's auc: 0.604941\n",
      "TRAIN: [       0        1        2 ... 12874342 12874343 12874344] \n",
      "TEST: [10299477 10299478 10299479 ... 11586908 11586909 11586910]\n",
      "2018-07-22 18:12:00.874632  FOLD  9\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.584186\n",
      "[10]\tvalid_0's auc: 0.588692\n",
      "[15]\tvalid_0's auc: 0.592792\n",
      "[20]\tvalid_0's auc: 0.595695\n",
      "[25]\tvalid_0's auc: 0.596303\n",
      "[30]\tvalid_0's auc: 0.598442\n",
      "[35]\tvalid_0's auc: 0.600242\n",
      "[40]\tvalid_0's auc: 0.601172\n",
      "[45]\tvalid_0's auc: 0.602664\n",
      "[50]\tvalid_0's auc: 0.6042\n",
      "[55]\tvalid_0's auc: 0.60474\n",
      "[60]\tvalid_0's auc: 0.605799\n",
      "[65]\tvalid_0's auc: 0.606663\n",
      "[70]\tvalid_0's auc: 0.607077\n",
      "[75]\tvalid_0's auc: 0.607564\n",
      "[80]\tvalid_0's auc: 0.607751\n",
      "[85]\tvalid_0's auc: 0.608102\n",
      "[90]\tvalid_0's auc: 0.608241\n",
      "[95]\tvalid_0's auc: 0.608474\n",
      "[100]\tvalid_0's auc: 0.608691\n",
      "[105]\tvalid_0's auc: 0.60899\n",
      "[110]\tvalid_0's auc: 0.609332\n",
      "[115]\tvalid_0's auc: 0.609474\n",
      "[120]\tvalid_0's auc: 0.609744\n",
      "[125]\tvalid_0's auc: 0.609878\n",
      "[130]\tvalid_0's auc: 0.610122\n",
      "[135]\tvalid_0's auc: 0.610022\n",
      "[140]\tvalid_0's auc: 0.610249\n",
      "[145]\tvalid_0's auc: 0.610223\n",
      "[150]\tvalid_0's auc: 0.610291\n",
      "[155]\tvalid_0's auc: 0.610269\n",
      "[160]\tvalid_0's auc: 0.610329\n",
      "[165]\tvalid_0's auc: 0.610487\n",
      "[170]\tvalid_0's auc: 0.610718\n",
      "[175]\tvalid_0's auc: 0.610762\n",
      "[180]\tvalid_0's auc: 0.610861\n",
      "[185]\tvalid_0's auc: 0.610955\n",
      "[190]\tvalid_0's auc: 0.611008\n",
      "[195]\tvalid_0's auc: 0.611099\n",
      "[200]\tvalid_0's auc: 0.611181\n",
      "[205]\tvalid_0's auc: 0.611169\n",
      "[210]\tvalid_0's auc: 0.611292\n",
      "[215]\tvalid_0's auc: 0.611488\n",
      "[220]\tvalid_0's auc: 0.611457\n",
      "[225]\tvalid_0's auc: 0.611569\n",
      "[230]\tvalid_0's auc: 0.611648\n",
      "[235]\tvalid_0's auc: 0.61184\n",
      "[240]\tvalid_0's auc: 0.611762\n",
      "[245]\tvalid_0's auc: 0.61186\n",
      "[250]\tvalid_0's auc: 0.61174\n",
      "[255]\tvalid_0's auc: 0.611868\n",
      "[260]\tvalid_0's auc: 0.611958\n",
      "[265]\tvalid_0's auc: 0.611766\n",
      "[270]\tvalid_0's auc: 0.612038\n",
      "[275]\tvalid_0's auc: 0.612185\n",
      "[280]\tvalid_0's auc: 0.612238\n",
      "[285]\tvalid_0's auc: 0.612319\n",
      "[290]\tvalid_0's auc: 0.612457\n",
      "[295]\tvalid_0's auc: 0.612298\n",
      "[300]\tvalid_0's auc: 0.612256\n",
      "[305]\tvalid_0's auc: 0.612278\n",
      "[310]\tvalid_0's auc: 0.612334\n",
      "[315]\tvalid_0's auc: 0.612342\n",
      "[320]\tvalid_0's auc: 0.612697\n",
      "[325]\tvalid_0's auc: 0.612504\n",
      "[330]\tvalid_0's auc: 0.612556\n",
      "[335]\tvalid_0's auc: 0.612664\n",
      "[340]\tvalid_0's auc: 0.612704\n",
      "[345]\tvalid_0's auc: 0.612631\n",
      "[350]\tvalid_0's auc: 0.612688\n",
      "[355]\tvalid_0's auc: 0.612684\n",
      "[360]\tvalid_0's auc: 0.612677\n",
      "[365]\tvalid_0's auc: 0.612669\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's auc: 0.61276\n",
      "TRAIN: [       0        1        2 ... 11586908 11586909 11586910] \n",
      "TEST: [11586911 11586912 11586913 ... 12874342 12874343 12874344]\n",
      "2018-07-22 19:00:31.169032  FOLD  10\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[5]\tvalid_0's auc: 0.601364\n",
      "[10]\tvalid_0's auc: 0.60335\n",
      "[15]\tvalid_0's auc: 0.60361\n",
      "[20]\tvalid_0's auc: 0.60379\n",
      "[25]\tvalid_0's auc: 0.606946\n",
      "[30]\tvalid_0's auc: 0.60984\n",
      "[35]\tvalid_0's auc: 0.612016\n",
      "[40]\tvalid_0's auc: 0.613184\n",
      "[45]\tvalid_0's auc: 0.613652\n",
      "[50]\tvalid_0's auc: 0.6145\n",
      "[55]\tvalid_0's auc: 0.614883\n",
      "[60]\tvalid_0's auc: 0.615833\n",
      "[65]\tvalid_0's auc: 0.615975\n",
      "[70]\tvalid_0's auc: 0.616519\n",
      "[75]\tvalid_0's auc: 0.617003\n",
      "[80]\tvalid_0's auc: 0.617284\n",
      "[85]\tvalid_0's auc: 0.617811\n",
      "[90]\tvalid_0's auc: 0.61815\n",
      "[95]\tvalid_0's auc: 0.618551\n",
      "[100]\tvalid_0's auc: 0.618904\n",
      "[105]\tvalid_0's auc: 0.619386\n",
      "[110]\tvalid_0's auc: 0.619484\n",
      "[115]\tvalid_0's auc: 0.619761\n",
      "[120]\tvalid_0's auc: 0.61975\n",
      "[125]\tvalid_0's auc: 0.61993\n",
      "[130]\tvalid_0's auc: 0.620289\n",
      "[135]\tvalid_0's auc: 0.620704\n",
      "[140]\tvalid_0's auc: 0.620681\n",
      "[145]\tvalid_0's auc: 0.620742\n",
      "[150]\tvalid_0's auc: 0.620773\n",
      "[155]\tvalid_0's auc: 0.62092\n",
      "[160]\tvalid_0's auc: 0.620981\n",
      "[165]\tvalid_0's auc: 0.621031\n",
      "[170]\tvalid_0's auc: 0.62135\n",
      "[175]\tvalid_0's auc: 0.621199\n",
      "[180]\tvalid_0's auc: 0.621325\n",
      "[185]\tvalid_0's auc: 0.621299\n",
      "[190]\tvalid_0's auc: 0.621549\n",
      "[195]\tvalid_0's auc: 0.621681\n",
      "[200]\tvalid_0's auc: 0.621929\n",
      "[205]\tvalid_0's auc: 0.622094\n",
      "[210]\tvalid_0's auc: 0.622122\n",
      "[215]\tvalid_0's auc: 0.622151\n",
      "[220]\tvalid_0's auc: 0.62224\n",
      "[225]\tvalid_0's auc: 0.62232\n",
      "[230]\tvalid_0's auc: 0.62243\n",
      "[235]\tvalid_0's auc: 0.622565\n",
      "[240]\tvalid_0's auc: 0.622587\n",
      "[245]\tvalid_0's auc: 0.622641\n",
      "[250]\tvalid_0's auc: 0.622815\n",
      "[255]\tvalid_0's auc: 0.622766\n",
      "[260]\tvalid_0's auc: 0.62278\n",
      "[265]\tvalid_0's auc: 0.622737\n",
      "[270]\tvalid_0's auc: 0.622635\n",
      "[275]\tvalid_0's auc: 0.622397\n",
      "[280]\tvalid_0's auc: 0.622404\n",
      "[285]\tvalid_0's auc: 0.622464\n",
      "[290]\tvalid_0's auc: 0.622469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295]\tvalid_0's auc: 0.622522\n",
      "[300]\tvalid_0's auc: 0.622614\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's auc: 0.622815\n",
      "CPU times: user 4d 18h 57min 29s, sys: 17min 58s, total: 4d 19h 15min 28s\n",
      "Wall time: 8h 26min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "iter_counter = 0\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "print(datetime.now(), 'start reading')\n",
    "\n",
    "for df in pd.read_table('mlboot_dataset/mlboot_data.tsv.gz', header=None, chunksize=chunksize):\n",
    "    \n",
    "    print(datetime.now(), 'read')\n",
    "    \n",
    "    iter_counter = iter_counter + 1    \n",
    "    print(datetime.now(), ' Iteration: ', iter_counter)\n",
    "    \n",
    "    df = df.merge(df.groupby(0)[0].count().reset_index(name = 'tx'), how = 'left')\n",
    "    \n",
    "    df['var'] = df.groupby(0)[5].transform('var')\n",
    "    \n",
    "    print(datetime.now(), 'entering train/test')\n",
    "    \n",
    "    dfm_train = df.merge(answers, left_on=0, right_on='cuid', how='inner')\n",
    "    dfm_test = df.merge(testdf, left_on=0, right_on='cuid', how='inner')\n",
    "    \n",
    "    dfm_train_len = dfm_train.shape[0]\n",
    "    dfm2 = dfm_train.append(dfm_test)\n",
    "    dfm_train_len, dfm2.shape\n",
    "    \n",
    "    print(datetime.now(), 'train/test created')\n",
    "    \n",
    "    dfm2['semicolon2'] = dfm2[2].fillna('').apply(lambda x: x.count(\":\"))\n",
    "    dfm2['ones2'] = dfm2[2].fillna('').apply(lambda x: x.count(\":1\"))\n",
    "    dfm2['twos2'] = dfm2[2].fillna('').apply(lambda x: x.count(\":2\"))\n",
    "    \n",
    "    dfm2['semicolon3'] = dfm2[3].fillna('').apply(lambda x: x.count(\":\"))\n",
    "    dfm2['ones3'] = dfm2[3].fillna('').apply(lambda x: x.count(\":1\"))\n",
    "    dfm2['twos3'] = dfm2[3].fillna('').apply(lambda x: x.count(\":2\"))\n",
    "    \n",
    "    dfm2['semicolon4'] = dfm2[4].fillna('').apply(lambda x: x.count(\":\"))\n",
    "    dfm2['ones4'] = dfm2[4].fillna('').apply(lambda x: x.count(\":1\"))\n",
    "    dfm2['twos4'] = dfm2[4].fillna('').apply(lambda x: x.count(\":2\"))\n",
    "    \n",
    "    print(datetime.now(), 'entering tfidf')\n",
    "        \n",
    "    dfm2[2].fillna('{}', inplace=True)\n",
    "    dfm2_2 = TfidfVectorizer(ngram_range=(1, 2), max_features=50_000).fit_transform(dfm2[2].fillna(''))\n",
    "    \n",
    "    print(datetime.now(), '2 tfidf done')\n",
    "    \n",
    "    dfm2[3].fillna('{}', inplace=True)\n",
    "    dfm2_3 = TfidfVectorizer(ngram_range=(1, 2), max_features=50_000).fit_transform(dfm2[3].fillna(''))\n",
    "    \n",
    "    print(datetime.now(), '3 tfidf done')\n",
    "    \n",
    "    dfm2[4].fillna('{}', inplace=True)\n",
    "    dfm2_4 = TfidfVectorizer(ngram_range=(1, 2), max_features=50_000).fit_transform(dfm2[4].fillna(''))\n",
    "    \n",
    "    print(datetime.now(), 'hstack')\n",
    "    \n",
    "    dfms = scipy.sparse.hstack([dfm2['tx'].values.reshape(-1,1), dfm2['var'].values.reshape(-1,1), dfm2['semicolon2'].values.reshape(-1,1), dfm2['ones2'].values.reshape(-1,1), dfm2['twos2'].values.reshape(-1,1), dfm2['semicolon3'].values.reshape(-1,1), dfm2['ones3'].values.reshape(-1,1), dfm2['twos3'].values.reshape(-1,1), dfm2['semicolon4'].values.reshape(-1,1), dfm2['ones4'].values.reshape(-1,1), dfm2['twos4'].values.reshape(-1,1),dfm2_2, dfm2_3, dfm2_4, dfm2[1].values.reshape(-1,1), dfm2[5].values.reshape(-1,1)]).tocsr()\n",
    "\n",
    "    y_train = dfm2['target'][:dfm_train_len].astype(int)\n",
    "    X_train = dfms[:dfm_train_len]\n",
    "    X_test = dfms[dfm_train_len:]\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    foldno = 0\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=10, shuffle=False)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "        X_tr, X_va = X_train[train_index], X_train[test_index]\n",
    "        y_tr, y_va = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "        #X_tr, X_va, y_tr, y_va = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=False)\n",
    "        X_te = X_test\n",
    "        #X_tr.shape, X_te.shape, X_va.shape\n",
    "        \n",
    "        foldno = foldno + 1\n",
    "\n",
    "        print(datetime.now(), ' FOLD ', foldno)\n",
    "\n",
    "\n",
    "        tr_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "        va_data = lgb.Dataset(X_va, label=y_va, reference=tr_data)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        parameters = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            #'num_leaves': 17,\n",
    "            #'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.5,\n",
    "            #'bagging_fraction': 0.9,\n",
    "            'bagging_freq': 4,\n",
    "            'verbose': 10\n",
    "        }\n",
    "\n",
    "        model = lgb.train(parameters,\n",
    "                          tr_data,\n",
    "                          valid_sets=va_data,\n",
    "                          num_boost_round=2500,\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose_eval=5)\n",
    "\n",
    "        res['cuid'] = dfm2[0][dfm_train_len:]\n",
    "        res['target'] = model.predict(X_test)\n",
    "\n",
    "        result = result.append(res)\n",
    "        \n",
    "        result.to_csv('result_'+str(foldno)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: 'cuid' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "resultdf = result.groupby('cuid').mean()\n",
    "        \n",
    "resultdf['cuid'] = resultdf.index\n",
    "testdf = testdf.merge(resultdf, left_on='cuid', right_on='cuid', how='outer')\n",
    "testdf.sample(4)\n",
    "\n",
    "testdf['target'].to_csv('kfold10.tsv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
